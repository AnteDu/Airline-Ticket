---
title: "predict entering"
author: "Ante Du"
output: pdf_document
---
Use the package that we need
```{r}
suppressMessages(library(tidyverse))
library(glmnet)
library(knitr)
library(Lahman)
library(dplyr)
library(class)
library(DMwR)
library(ggplot2)
```
0.Load the dataset and set seed
  set test set and use the rest set to finish 1-6
```{r}
load("/Users/ante/Desktop/ML\ PS3/ML\ PS3/market_airline_level.R")
load("/Users/ante/Desktop/ML\ PS3/ML\ PS3/market_level.R")
set.seed(0)
test <- sample(nrow(datam), size = 1000)
testset <- datam[test,]
rest <- datam[-test,]
```
1.Linear model:if AA enters a market as function of number of competitors
```{r}
AA<- 
  datama %>%
  filter(ticket_carrier=="AA") %>%
  select(-price:-market_income) #leave the variable that we need
marketAA<-#merge market level and airline level dataset
  left_join(rest,AA, by = c("origin_airport_id"="origin_airport_id",
                            "dest_airport_id"="dest_airport_id"))
marketAA$AA=1*(marketAA$ticket_carrier=="AA")#set AA as dummy vaiable
marketAA <- select(marketAA, -ticket_carrier)
marketAA[is.na(marketAA)] <-0
marketAA <- # get competitors covariance
  marketAA %>%
  mutate(noc = num_carriers - AA)
linear <- lm(AA ~ noc, data = marketAA, x = TRUE)  
summary(linear)
```
2.Finish 1 in logit model
```{r}
logit <- glm(AA ~ noc, family = binomial(link ="logit"),data = marketAA, x = TRUE)
summary(logit)
```
3.Finish 2 in probit model
```{r}
probit <- glm(AA ~ noc, family = binomial(link = "probit"), data = marketAA, x = TRUE)
summary(probit)
```
4.Non-parametric estimates of the conditional probabilities of entering
```{r}
enoc <-sort(unique(marketAA$noc))
for(i in enoc){ #use for loop to compute to each number competitor,
  poec <- marketAA %>% #conditional probabilities of entering
  filter(noc == i) 
  sum = sum((poec$AA == 1)/nrow(poec))
  cat("conditional probability in ",i,": ")
  cat(sum, "\n")
}
```
5.Plot the fitted values of each regression in one graph
```{r}
p <- ggplot(marketAA, aes(noc, AA))
predicted.data <- as.data.frame(predict(linear, newdata = marketAA, 
                                        type="response", se=TRUE))
predicted.data1 <- as.data.frame(predict(logit, newdata = marketAA, 
                                        type="response", se=TRUE))
predicted.data2 <- as.data.frame(predict(probit, newdata = marketAA, 
                                        type="response", se=TRUE))
new.data <- cbind(marketAA, predicted.data)
new.data1 <- cbind(marketAA, predicted.data1)
new.data2 <- cbind(marketAA, predicted.data2)
p + geom_point() + geom_line(data=new.data, aes(y=fit,x=noc)) + 
geom_line(data=new.data1, aes(y=fit)) + 
geom_line(data = new.data2, aes(y = fit)) + ylim(0,1)

```
6.Expect the number of competitor, add other covariances to the regression,
and use data L1 regularized logistic regression to find the optimal value
of lambda
```{r}
CM<- as.formula(AA ~ noc + average_distance_m + market_size + hub_route +vacation_route + slot_controlled
+ market_income +  (noc + average_distance_m + market_size + hub_route +vacation_route + slot_controlled 
          + market_income)^2)#add other covariances to regression

X <- model.matrix(CM, marketAA)
Y <- marketAA$AA
cv.out <- cv.glmnet(X,Y,alpha=1,family='binomial',type.measure = 'mse', nfolds = 10)#use cross validation procedure
plot(cv.out)
lambda_min <- cv.out$lambda.min#find fittest lambda
str(lambda_min)
coef(cv.out,s=lambda_min)
lasso <-glmnet(X,Y,lambda = lambda_min, family = "binomial")

```
7.Calculate the sum of squared prediction errors on the test set for each 
of your 5 models.
```{r}
testAA<-left_join(testset,AA, by=c("origin_airport_id"="origin_airport_id",
                                 "dest_airport_id"="dest_airport_id"))
testAA$AA = 1*(testAA$ticket_carrier=="AA")
testAA <- select(testAA, -ticket_carrier)
testAA[is.na(testAA)] <- 0
testAA <- testAA %>% mutate(noc = num_carriers - AA)
LMmse <- mean((testAA$AA - predict(linear, newdata=testAA, type='response')) ^ 2) #squared predition errors of linear model
model_selection = data.frame(model = "Simple linear model",
                             mse = LMmse,
                             stringsAsFactors = FALSE)
LogitMse <- mean((testAA$AA -  predict(logit, newdata=testAA, type='response')) ^ 2)#squared predition errors of logit model
model_selection[2,] <- list(model = "Simple logit model", LogitMse)
ProbitMse <- mean((testAA$AA - predict(probit, newdata=testAA, type='response')) ^ 2)
model_selection[3,] <- list(model = "Simple probit model", ProbitMse)
#squared predition errors of probit model
inx <- 1
cp <- 1:1000
for(i in testAA$noc){# use for loop to repeat 5 for test set
  if (i == 1) cp[inx] = 0.1010526
  else if (i == 2) cp[inx] = 0.5602837
  else if (i == 3) cp[inx] = 0.8250444
  else if (i == 4) cp[inx] = 0.9443787
  else if (i == 5) cp[inx] = 0.9500609
  else if (i == 6) cp[inx] = 0.9898305
  else cp[inx] = 1
  inx = inx + 1
}
Pmse <- mean((testAA$AA - cp) ^ 2)
model_selection[4,] <- list(model = "Conditional probability model", Pmse)
#squared predition errors of non parameteric model
test <- model.matrix(CM,testAA)
lasso_prob <- predict(cv.out,newx = test, type='response')
Lmse <- mean((testAA$AA-lasso_prob)^2)                          
model_selection[5,] <- list(model = "CV Lasso Regularized Logistic", Lmse)
#squared predition errors of lasso model
model_selection
```



